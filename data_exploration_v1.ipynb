{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A notebook for data exploration and function testing for predict sales web app "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents:\n",
    "1. Data exploration\n",
    "2. Feature engineering and train,test and predict split\n",
    "3. Creating a base estimator to compare with\n",
    "4. Creating and testing linear model\n",
    "5. Creating and testing XGBoost model \n",
    "6. Tuning parameters and getting feature importance for the best model \n",
    "7. Testing on unseen shops\n",
    "8. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A long cell with functions from app/process_data.py - you can ignore it and scroll past "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def preprocess_data(sales_filepath, items_filepath, use_shop_ids=[38,42,35,23,32,24,4,5,12,29]):\n",
    "    '''\n",
    "        preprocess_data() - function that transforms initial training data CSV files into a dataframe \n",
    "                            in a format that can be then processed and used in training pipeline\n",
    "        Input:\n",
    "            sales_filepath - (str) path to training sales data \n",
    "            items_filepath - (str) path to training data on items (names, categories)\n",
    "            use_shop_ids - (list) a subset of int shop ids from 'sales_filepath' CSV file to use during training to reduce training time\n",
    "        Output:\n",
    "            data - (pd.DataFrame) a Pandas dataframe with sales data\n",
    "\n",
    "    '''\n",
    "    sales_train = pd.read_csv(sales_filepath)\n",
    "    items = pd.read_csv(items_filepath)\n",
    "    data = sales_train[sales_train['shop_id'].isin(use_shop_ids) ].drop(columns=['date_block_num']).reset_index(drop=True)\n",
    "    data = pd.merge(data, items, on=['item_id'], how='left')    \n",
    "\n",
    "    return data\n",
    "\n",
    "def check_data_correctnes(data):\n",
    "    '''\n",
    "        check_data_correctnes() - function that checks correctness of a dataframe format and data, and assigns a shop_id if none is given\n",
    "                                  in case of a single shop in the data\n",
    "        Input:\n",
    "            data - (pd.DataFrame) a Pandas dataframe with sales data\n",
    "            Needed columns are: date, shop_id, item_id, item_price, item_cnt_day, item_name, item_category_id\n",
    "        Output:\n",
    "            data - (pd.DataFrame) a Pandas dataframe with sales data with necessary changes if needed (add shop_id if empty),\n",
    "            OR\n",
    "            raises an exception to let the web app know that format is incorrect \n",
    "    '''\n",
    "    data['shop_id'] = data['shop_id'].fillna('shop1')\n",
    "    return data\n",
    "\n",
    "def clean_and_aggreagate(data):\n",
    "    '''\n",
    "        clean_and_aggreagate() - function that cleanes, aggregates and sorts a Pandas dataframe for training or predicting sales\n",
    "        Input:\n",
    "            data - (pd.DataFrame) a Pandas dataframe with sales data\n",
    "        Output:\n",
    "            data_monthly - (pd.DataFrame) a cleaned and aggregated sorted dataframe\n",
    "    '''\n",
    "\n",
    "    # delete data with negative item counts or prices\n",
    "    data = data[data['item_cnt_day']>0]\n",
    "    data = data[data['item_price']>0]\n",
    "    # clean from any null values\n",
    "    data = data.dropna()\n",
    "    \n",
    "    # convert date from string to datetime format\n",
    "    data['date'] = pd.to_datetime(data['date'], format='%d.%m.%Y')\n",
    "\n",
    "    # Add month and year and aggregate data\n",
    "    data['month'] = data['date'].dt.month\n",
    "    data['year'] = data['date'].dt.year\n",
    "\n",
    "    # making sure we are getting only needed columns\n",
    "    keep_columns_agg = ['shop_id', 'item_id', 'item_price', 'item_cnt_day', 'month', 'year', 'item_category_id']\n",
    "    \n",
    "    # aggregate data monthly and by shops and items \n",
    "    data_monthly = data[keep_columns_agg].groupby(['year','month', 'shop_id', 'item_category_id', 'item_id'], as_index=False).agg(\n",
    "        {'item_price':'mean', \n",
    "        'item_cnt_day':['sum', 'mean'] })\n",
    "\n",
    "    # make multilevel index flat\n",
    "    data_monthly.columns = data_monthly.columns.map(''.join)\n",
    "\n",
    "    # rename columns\n",
    "    data_monthly = data_monthly.rename(columns={\n",
    "        'item_pricemean': 'item_price_avg', \n",
    "        'item_cnt_daysum':'item_cnt_month',\n",
    "        'item_cnt_daymean':'item_cnt_day_mean'})\n",
    "    \n",
    "    # sort the dataframe for future analysis\n",
    "    data_monthly = data_monthly.sort_values(by=['year', 'month', 'shop_id', 'item_id']).reset_index(drop=True)\n",
    "\n",
    "    return data_monthly\n",
    "\n",
    "def add_empty_rows(data_monthly):\n",
    "    '''\n",
    "        add_empty_rows() - function that extends a dataframe of aggregated sales with skipped rows\n",
    "                           so that the dataframe has explicit data on zero sales (sets 'item_cnt_month' to zero) \n",
    "                           instead of not mentioning an item for a particular month in a particular shop\n",
    "        Input:\n",
    "            data_monthly - (pd.DataFrame) sorted Pandas dataframe with aggregated sales data\n",
    "        Output:\n",
    "            data_monthly_ext - (pd.DataFrame) extended dataframe with explicit 0 rows\n",
    "    '''\n",
    "    item_ids = data_monthly['item_id'].unique()\n",
    "    shop_ids = data_monthly['shop_id'].unique()\n",
    "\n",
    "    start_date_year = int(data_monthly.iloc[0,:]['year'])\n",
    "    start_date_month = int(data_monthly.iloc[0,:]['month'])\n",
    "    end_date_year = int(data_monthly.iloc[-1,:]['year'])\n",
    "    end_date_month = int(data_monthly.iloc[-1,:]['month'])\n",
    "\n",
    "    # --- calculate total number of months in the period of historical data\n",
    "    number_of_months = (end_date_year - start_date_year) * 12 + (end_date_month - start_date_month) + 1\n",
    "\n",
    "    # will have data on all possible combinations of sales records\n",
    "    # for given shops, items and given time period \n",
    "    zero_rows = []\n",
    "    cur_month = start_date_month\n",
    "    cur_year = start_date_year\n",
    "\n",
    "    for i in range(number_of_months):\n",
    "        for shop in shop_ids:\n",
    "            for item in item_ids:\n",
    "                # adding a row - transaction for certain shop, year, month and item that will be zeroes initially\n",
    "                # and then joined with main data so that main data has explicit zeros as transactions\n",
    "                row = [cur_year, cur_month, shop, item]\n",
    "                zero_rows.append(row)\n",
    "        \n",
    "        # create a correction coeeficient for the case of December, 12th month, so that we het 12 and not 0\n",
    "        add_12_if_receive_0 = (12 - 12*math.ceil((cur_month+1)%12 / 12))\n",
    "        # increase month by 1, make sure it will be in [1,12] range\n",
    "        cur_month = (cur_month+1)%12 + add_12_if_receive_0\n",
    "        \n",
    "        # increase year if we arrived to the 1st month, January, after increasing month\n",
    "        if cur_month == 1:\n",
    "            cur_year += 1\n",
    "\n",
    "    # create a df of zero rows    \n",
    "    zero_rows = pd.DataFrame(zero_rows, columns=['year', 'month', 'shop_id', 'item_id'])\n",
    "\n",
    "    # merge zero rows with the main data, data_monthly\n",
    "    data_monthly_ext = pd.merge(zero_rows, data_monthly, on=['year','month', 'shop_id','item_id'], how='left')\n",
    "    # fill missing records with 0s\n",
    "    data_monthly_ext.fillna(0, inplace=True)\n",
    "    # make sure the dataframe is sorted\n",
    "    data_monthly_ext = data_monthly_ext.sort_values(by=['year', 'month', 'shop_id', 'item_id']).reset_index(drop=True)\n",
    "\n",
    "    return data_monthly_ext\n",
    "\n",
    "def add_global_features(data_monthly_ext):\n",
    "    '''\n",
    "        add_global_features() - function that adds features for training and predicting purposes.\n",
    "                                I called features global becasue they can be applied to the whole data\n",
    "                                before splitting into train and test without any data leakage in terms of forecasting\n",
    "        Input:\n",
    "            data_monthly_ext - (pd.DataFrame) a sorted by year and month Pandas dataframe with aggregated sales data\n",
    "        Output:\n",
    "            data_monthly_ext - (pd.DataFrame) initial dataframe with new features\n",
    "    '''\n",
    "    # --- add date_block to split data into train and test\n",
    "    start_month = data_monthly_ext.iloc[0,:]['month']\n",
    "    start_year = data_monthly_ext.iloc[0,:]['year']\n",
    "\n",
    "    # order of the starting month - we will subtract it from other month to understand how many month we moved forward\n",
    "    starting_month_agg = start_year*12 + start_month\n",
    "    # create arrays of year and month to perform calculations on them using np.vectorize\n",
    "    years = np.array(data_monthly_ext['year'])\n",
    "    months = np.array(data_monthly_ext['month'])\n",
    "    # for better performance create a vectorized function that computes block number (order of month from starting month)\n",
    "    calculate_block_num = np.vectorize(lambda year, month: (year*12 + month)- starting_month_agg)\n",
    "    # number of months since year 0 in starting date - this will be subtracted to understand how many months we have moved ahead from start\n",
    "    data_monthly_ext['date_block_num'] = calculate_block_num(years, months)\n",
    "\n",
    "    # Feature engineering\n",
    "    # add rolling statistics\n",
    "\n",
    "    # define size of a rolling window\n",
    "    rolling_window_size = 3\n",
    "    # --- Calculate rolling statistics\n",
    "\n",
    "    function_mean = lambda column: column.rolling(window=rolling_window_size, min_periods=1).mean()\n",
    "\n",
    "    data_monthly_ext['item_cnt_roll_mean'] = data_monthly_ext.groupby(['shop_id','item_id'])['item_cnt_month'].apply(function_mean)\n",
    "    \n",
    "    # store average number of items sold per month for each item in a shop up to this point using pd.expanding function\n",
    "    data_monthly_ext['shop_item_mean_past'] = data_monthly_ext.groupby(['shop_id', 'item_id'])[['item_cnt_month']].expanding().mean().values\n",
    "    \n",
    "    # store average number of items sold per month for each year up to this point using pd.expanding function\n",
    "    data_monthly_ext['year_mean_past'] = data_monthly_ext.groupby(['year'])[['item_cnt_month']].expanding().mean().values\n",
    "    \n",
    "    # store average number of items sold per month for each month up to this point using pd.expanding function\n",
    "    data_monthly_ext['month_mean_past'] = data_monthly_ext.groupby(['month'])[['item_cnt_month']].expanding().mean().values\n",
    "\n",
    "\n",
    "    # let us calculate lags for the past 3 months\n",
    "    number_lags = range(1,4)\n",
    "\n",
    "    # --- generate shifted number of items sold from the past 1-3 months\n",
    "    for lag in number_lags:\n",
    "        feature_name = 'item_cnt_shifted{}'.format(lag)\n",
    "        data_monthly_ext[feature_name] = data_monthly_ext.sort_values('date_block_num').groupby(['shop_id', 'item_id'])['item_cnt_month'].shift(lag)\n",
    "        # Fill the empty shifted features with 0\n",
    "        data_monthly_ext[feature_name] = data_monthly_ext[feature_name].fillna(0)\n",
    "\n",
    "    # generate trend which shows the change in item sales count\n",
    "    # trend = current - (previous_1 + ... + previous_n)/n = n*current - previous_1 - ... - previous_n, in our case n=3\n",
    "    # initially fill with current sales multiplied by number of times we will substract previous values to get average\n",
    "    data_monthly_ext['item_trend'] = len(number_lags) * data_monthly_ext['item_cnt_month']\n",
    "    # then subtract previous n values\n",
    "    for lag in number_lags:\n",
    "        feature_name = 'item_cnt_shifted{}'.format(lag)\n",
    "        data_monthly_ext['item_trend'] -= data_monthly_ext[feature_name]\n",
    "    # then divide by the number of times we have subtracted previous values to get average\n",
    "    data_monthly_ext['item_trend'] /= len(number_lags) \n",
    "\n",
    "    return data_monthly_ext\n",
    "\n",
    "\n",
    "def add_labels(data_monthly_ext):\n",
    "    '''\n",
    "        add_labels() - function that creates labels = a column of values we will predict = sales next month for an item in a shop\n",
    "        Input:\n",
    "            data_monthly_ext - (pd.DataFrame) a Pandas dataframe with aggregated sorted sales data\n",
    "        Output:\n",
    "            data_monthly_ext - (pd.DataFrame) dataframe with new column - 'itm_cnt_nxt_mnth', which is sales next month for an item in a shop\n",
    "    '''\n",
    "    data_monthly_ext['itm_cnt_nxt_mnth'] = data_monthly_ext.groupby(['shop_id', 'item_id'])['item_cnt_month'].shift(-1)\n",
    "    return data_monthly_ext\n",
    "\n",
    "def split_train_test_predict(data_monthly_ext):\n",
    "    '''\n",
    "        split_train_test_predict() - function that splits data into train, test and predict, where predict - is the last available month in the data,\n",
    "                       and for which we will be generating prediction for the next, unknown to us month. Test will be used to see how good is the model.\n",
    "                       Since we are dealing with timeseries, we cannot simply randomly split data. We also want to split exactly by month periods, so the standard \n",
    "                       split function will not work.\n",
    "        Input:\n",
    "            data_monthly - (pd.DataFrame) a Pandas dataframe with aggregated sales data\n",
    "        Output:\n",
    "            train_set - (pd.DataFrame) training data\n",
    "            test_set - (pd.DataFrame) testing data to see how we performed\n",
    "            predict_set - (pd.DataFrame) set of sales for the last month for which we will predict future sales for the next unseen month\n",
    "    '''\n",
    "    # calculate date_block_num for splitting\n",
    "    num_months = data_monthly_ext['date_block_num'].max() + 1\n",
    "    # starting from the 3rd month as we have rolling statistics with 3 month window (date_block_num starts with 0)\n",
    "    train_low = 3 - 1\n",
    "    # get approximately 70% of the data\n",
    "    train_high = int(0.7 * num_months) - 1\n",
    "    # testing data will have all the rest of the month up to a last one, which is used for predictiong as it does not have data on next month sales\n",
    "    test_high = num_months - 1\n",
    "\n",
    "    train_set = data_monthly_ext[(data_monthly_ext['date_block_num'] >= train_low) & (data_monthly_ext['date_block_num'] <= train_high )].copy()\n",
    "    test_set = data_monthly_ext[(data_monthly_ext['date_block_num'] > train_high) & (data_monthly_ext['date_block_num'] < test_high )].copy()\n",
    "    predict_set = data_monthly_ext[data_monthly_ext['date_block_num'] == test_high].copy()\n",
    "\n",
    "    # in train and test get rid of the null values in target variable\n",
    "    train_set = train_set.dropna(subset=['itm_cnt_nxt_mnth'])\n",
    "    test_set = test_set.dropna(subset=['itm_cnt_nxt_mnth'])\n",
    "\n",
    "    return train_set, test_set, predict_set\n",
    "\n",
    "\n",
    "\n",
    "def add_set_features(train, test):\n",
    "    '''\n",
    "        add_set_features() - function for more feature engineering done on each train and test sets to avoid data leakage.\n",
    "                            We will be calculating statistics based on the sales in the next month, so cannot use it on predict set as\n",
    "                            it does not have information on the future sales. On test set we are setting values calculated based on train data\n",
    "                            because we want to avoid data leakage and test data \"knowing\" about sales we want to predict.\n",
    "        Input:\n",
    "            train_set - (pd.DataFrame) training data\n",
    "            test_set - (pd.DataFrame) testing data to see how we performed\n",
    "        Output:\n",
    "            train_set - (pd.DataFrame) training data with new features\n",
    "            test_set - (pd.DataFrame) testing data with new features based on training data without data that can help forecast values on test,\n",
    "                        only past values from train are added here\n",
    "    '''\n",
    "    # each new feature will be a statistics computed by grouping and aggregating next month sales by certain dimensions\n",
    "    # we will generate that grouped statistics and then merge larger ungrouped train and test dataframes with it\n",
    "    # computing on train data for both train and test as we don't want to give away any information to test set\n",
    "    # as the calculations are done on future sale and since we are dealing with timeseries\n",
    "\n",
    "    def generate_statistics(dataset, group_by_columns, new_column_names, agg_column='itm_cnt_nxt_mnth', agg_function_names=['mean']):\n",
    "        '''\n",
    "            generate_statistics() - helper internal function for generating statistics of a dataset using grouping and aggregation\n",
    "            Input:\n",
    "                dataset - (pd.DataFrame) data frame to calculate statistics on\n",
    "                group_by_columns - (list of str) columns to group by\n",
    "                new_column_names - (list of str) how to name new resulting columns\n",
    "                agg_column - (str) on which column the calculation will be performed\n",
    "                agg_function_names - (list of str) which aggregate functions to use on 'agg_column' after grouping\n",
    "\n",
    "            Output:\n",
    "                res - (pd.DataFrame) dataframe with 'new_column_names' columns - result of grouping and applying aggreagate functions\n",
    "        '''\n",
    "        res = dataset.groupby(group_by_columns).agg({agg_column: agg_function_names})\n",
    "        res.columns = new_column_names\n",
    "        res.reset_index(inplace=True)\n",
    "        return res\n",
    "\n",
    "\n",
    "    # --- Add mean statistic features to train and test sets.\n",
    "\n",
    "    # Averages for each item across all shops, months and years\n",
    "    item_means = generate_statistics(train, ['item_id'], ['item_mean_future'])\n",
    "    train = pd.merge(train, item_means, on=['item_id'], how='left')\n",
    "    test = pd.merge(test, item_means, on=['item_id'], how='left')\n",
    "\n",
    "    # Averages for each item in each shop across all months and years\n",
    "    shop_item_means = generate_statistics(train, ['shop_id', 'item_id'], ['shop_item_mean_future'])\n",
    "    train = pd.merge(train, shop_item_means, on=['shop_id', 'item_id'], how='left')\n",
    "    test = pd.merge(test, shop_item_means, on=['shop_id', 'item_id'], how='left')\n",
    "    \n",
    "    # Averages for each category across all shops, months and years\n",
    "    category_means = generate_statistics(train, ['item_category_id'], ['category_mean_future'])\n",
    "    train = pd.merge(train, category_means, on=['item_category_id'], how='left')\n",
    "    test = pd.merge(test, category_means, on=['item_category_id'], how='left')\n",
    "    \n",
    "    # Averages for each month across all shops, years and items\n",
    "    month_means = generate_statistics(train, ['month'], ['month_mean_future'])\n",
    "    train = pd.merge(train, month_means, on=['month'], how='left')\n",
    "    test = pd.merge(test, month_means, on=['month'], how='left')\n",
    "    \n",
    "    # Fill the empty features with 0\n",
    "    train = train.fillna(0)\n",
    "    test = test.fillna(0)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def split_data_labels(train_set, test_set, predict_set):\n",
    "    '''\n",
    "        split_data_labels() - function that splits sets into data (features) and labels to predict, \n",
    "            specifically train and test into X_train, Y_train, X_test, Y_test \n",
    "            and also creates X_predict for prediction in the same format as X_train and X_test.\n",
    "            X_predict - is the last available month in the data, and for which we will be generating prediction for the next, unknown to us, month. \n",
    "            Test will be used to see how good is the model.\n",
    "            Since we are dealing with timeseries, we cannot simply randomly split data. We also want to split exactly by month periods, so the standard \n",
    "            split function will not work.\n",
    "        Input:\n",
    "            train_set - (pd.DataFrame) training data\n",
    "            test_set - (pd.DataFrame) testing data to see how we performed\n",
    "            predict_set - (pd.DataFrame) set of sales for the last month for which we will predict future sales for the next unseen month\n",
    "        Output:\n",
    "            X_train - (pd.DataFrame) training features\n",
    "            Y_train - (pd.DataFrame) training labels\n",
    "            X_test - (pd.DataFrame) testing features\n",
    "            Y_test - (pd.DataFrame) testing labels\n",
    "            X_predict - (pd.DataFrame) features for predicting unknown data  \n",
    "    '''\n",
    "    # create train and test sets and labels. \n",
    "    X_train = train_set.drop(['itm_cnt_nxt_mnth', 'date_block_num'], axis=1)\n",
    "    Y_train = train_set['itm_cnt_nxt_mnth'].astype(int)\n",
    "    X_test = test_set.drop(['itm_cnt_nxt_mnth', 'date_block_num'], axis=1)\n",
    "    Y_test = test_set['itm_cnt_nxt_mnth'].astype(int)\n",
    "    \n",
    "    # create X_predict to predct next unseen month\n",
    "    history = pd.concat([train_set, test_set]).drop_duplicates(subset=['item_id'], keep='last')\n",
    "    X_predict = pd.merge(predict_set, history, on=['item_id'], how='left', suffixes=['', '_'])\n",
    "    X_predict.drop('itm_cnt_nxt_mnth', axis=1, inplace=True)\n",
    "    X_predict = X_predict[X_train.columns]\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test, X_predict\n",
    "    \n",
    "\n",
    "def return_processed_data(data):\n",
    "    '''\n",
    "        return_processed_data() - function that combines all of the ETL steps for ML training and predicting.\n",
    "                                  Raises exception if datafile is not in needed format or has less than 6 month of data\n",
    "        Input:\n",
    "            data - (pd.DataFrame) dataframe with sales data.\n",
    "                    Needed columns are: date, shop_id, item_id, item_price, item_cnt_day, item_name, item_category_id\n",
    "        Output:\n",
    "            X_train - (pd.DataFrame) training features\n",
    "            Y_train - (pd.DataFrame) training labels\n",
    "            X_test - (pd.DataFrame) testing features\n",
    "            Y_test - (pd.DataFrame) testing labels\n",
    "            X_predict - (pd.DataFrame) data set (features) for predicting unknown data\n",
    "            extended_predict_set - (pd.DataFrame) data set for predicting data, like X_predict, but with all the original columns (like item_id and etc.) to return to a user later\n",
    "    '''\n",
    "    data = check_data_correctnes(data)\n",
    "    data_monthly = clean_and_aggreagate(data)\n",
    "    data_monthly_ext = add_empty_rows(data_monthly)\n",
    "    data_monthly_ext = add_global_features(data_monthly_ext)\n",
    "    data_monthly_ext = add_labels(data_monthly_ext)\n",
    "    train_set, test_set, predict_set = split_train_test_predict(data_monthly_ext)\n",
    "    train_set, test_set = add_set_features(train_set, test_set)\n",
    "    X_train, Y_train, X_test, Y_test, X_predict = split_data_labels(train_set, test_set, predict_set)\n",
    "\n",
    "\n",
    "    # --- select features that will be used for training, testing and predicting\n",
    "\n",
    "    features = ['shop_item_mean_future', 'item_cnt_month', 'item_trend', 'month_mean_future', 'item_cnt_roll_mean', 'item_cnt_day_mean', \n",
    "                'month_mean_past', 'item_mean_future', 'category_mean_future', 'shop_item_mean_past', 'year_mean_past']\n",
    "    # ---- Select subsets\n",
    "    # First, save the data we will be predicting before we will select features for modelling from it - 'extended_predict_set'. \n",
    "    # This will allow us to return prediction in a clear format to the user\n",
    "    extended_predict_set = X_predict\n",
    "    # --- subset other Xs            \n",
    "    X_train = X_train[features]\n",
    "    X_test = X_test[features]\n",
    "    X_predict = X_predict[features]\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test, X_predict, extended_predict_set\n",
    "\n",
    "def create_prediction_df(extended_predict_set, Y_predict, columns = ['year', 'month', 'shop_id', 'item_id', 'item_category_id', 'item_price_avg']):\n",
    "    '''\n",
    "        create_prediction_df() - a function that combines predicted target data (sales amount) with the data itself (shops, items, categories) into one Pandas dataframe\n",
    "        Input:\n",
    "            extended_predict_set - (pd.dataframe) dataframe with data (year, month, shops, items, categories, etc.)\n",
    "            Y_predict - (list or numpy array) dataframe with predicted sales count for the next month\n",
    "            columns = columns of extended_predict_set to keep\n",
    "        Output:\n",
    "            result_df - resulting df with combined data\n",
    "    '''    \n",
    "    result_df = extended_predict_set[columns].copy()\n",
    "\n",
    "    # get current month and year\n",
    "    cur_month = extended_predict_set['month'].iloc[0]\n",
    "    cur_year = extended_predict_set['year'].iloc[0]\n",
    "\n",
    "    # increase current month by 1 to output prediction\n",
    "    cur_month += 1\n",
    "    # check that we are less than 12, set to 1 if 13. '%' alone won't work as there is case of 12 that gives 0\n",
    "    if cur_month == 13:\n",
    "        cur_month = 1\n",
    "        # increae a year by one\n",
    "        cur_year += 1\n",
    "\n",
    "    result_df.loc[:,'year'] = cur_year\n",
    "    result_df.loc[:,'month'] = cur_month\n",
    "\n",
    "    # add predicted sales\n",
    "    result_df.loc[:,'predicted_number_items_sold'] =  Y_predict\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select shops to train on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess_data('data/sales_train.csv', 'data/items.csv', use_shop_ids=range(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1357300, 7)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agg = clean_and_aggreagate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price_avg</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>item_cnt_day_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>221.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>33</td>\n",
       "      <td>347.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>51</td>\n",
       "      <td>128.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  shop_id  item_category_id  item_id  item_price_avg  \\\n",
       "0  2013      1        0                40       32           221.0   \n",
       "1  2013      1        0                37       33           347.0   \n",
       "2  2013      1        0                40       35           247.0   \n",
       "3  2013      1        0                40       43           221.0   \n",
       "4  2013      1        0                57       51           128.5   \n",
       "\n",
       "   item_cnt_month  item_cnt_day_mean  \n",
       "0             6.0                1.5  \n",
       "1             3.0                1.0  \n",
       "2             1.0                1.0  \n",
       "3             1.0                1.0  \n",
       "4             2.0                1.0  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(745173, 8)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>745173.0</td>\n",
       "      <td>2013.778890</td>\n",
       "      <td>0.780940</td>\n",
       "      <td>2013.00</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>745173.0</td>\n",
       "      <td>6.090788</td>\n",
       "      <td>3.474579</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shop_id</th>\n",
       "      <td>745173.0</td>\n",
       "      <td>17.838409</td>\n",
       "      <td>8.586221</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_category_id</th>\n",
       "      <td>745173.0</td>\n",
       "      <td>41.338618</td>\n",
       "      <td>16.496649</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <td>745173.0</td>\n",
       "      <td>10547.819149</td>\n",
       "      <td>6250.862902</td>\n",
       "      <td>18.00</td>\n",
       "      <td>4907.0</td>\n",
       "      <td>10300.0</td>\n",
       "      <td>15996.0</td>\n",
       "      <td>22169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_price_avg</th>\n",
       "      <td>745173.0</td>\n",
       "      <td>821.537296</td>\n",
       "      <td>1608.297268</td>\n",
       "      <td>0.09</td>\n",
       "      <td>199.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>307980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_cnt_month</th>\n",
       "      <td>745173.0</td>\n",
       "      <td>2.298121</td>\n",
       "      <td>8.805831</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_cnt_day_mean</th>\n",
       "      <td>745173.0</td>\n",
       "      <td>1.085481</td>\n",
       "      <td>1.738946</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count          mean          std      min     25%  \\\n",
       "year               745173.0   2013.778890     0.780940  2013.00  2013.0   \n",
       "month              745173.0      6.090788     3.474579     1.00     3.0   \n",
       "shop_id            745173.0     17.838409     8.586221     0.00    10.0   \n",
       "item_category_id   745173.0     41.338618    16.496649     0.00    30.0   \n",
       "item_id            745173.0  10547.819149  6250.862902    18.00  4907.0   \n",
       "item_price_avg     745173.0    821.537296  1608.297268     0.09   199.0   \n",
       "item_cnt_month     745173.0      2.298121     8.805831     1.00     1.0   \n",
       "item_cnt_day_mean  745173.0      1.085481     1.738946     1.00     1.0   \n",
       "\n",
       "                       50%      75%       max  \n",
       "year                2014.0   2014.0    2015.0  \n",
       "month                  6.0      9.0      12.0  \n",
       "shop_id               19.0     25.0      29.0  \n",
       "item_category_id      40.0     55.0      83.0  \n",
       "item_id            10300.0  15996.0   22169.0  \n",
       "item_price_avg       399.0    899.0  307980.0  \n",
       "item_cnt_month         1.0      2.0    2253.0  \n",
       "item_cnt_day_mean      1.0      1.0    1000.0  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_agg.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price_avg</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>item_cnt_day_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>745168</th>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>22145</td>\n",
       "      <td>199.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745169</th>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>22154</td>\n",
       "      <td>299.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745170</th>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>22162</td>\n",
       "      <td>349.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745171</th>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>22163</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745172</th>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>49</td>\n",
       "      <td>22167</td>\n",
       "      <td>299.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  month  shop_id  item_category_id  item_id  item_price_avg  \\\n",
       "745168  2015     10       28                37    22145           199.0   \n",
       "745169  2015     10       28                37    22154           299.0   \n",
       "745170  2015     10       28                40    22162           349.0   \n",
       "745171  2015     10       28                40    22163           169.0   \n",
       "745172  2015     10       28                49    22167           299.0   \n",
       "\n",
       "        item_cnt_month  item_cnt_day_mean  \n",
       "745168             1.0                1.0  \n",
       "745169             1.0                1.0  \n",
       "745170             1.0                1.0  \n",
       "745171             1.0                1.0  \n",
       "745172             1.0                1.0  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_agg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions is 1357300\n"
     ]
    }
   ],
   "source": [
    "numb_transactions = data.shape[0]\n",
    "print('Number of transactions is {}'.format(numb_transactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of shops is 30\n"
     ]
    }
   ],
   "source": [
    "numb_shops = data_agg['shop_id'].nunique()\n",
    "print('Number of shops is {}'.format(numb_shops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories is 73\n"
     ]
    }
   ],
   "source": [
    "numb_categories = data_agg['item_category_id'].nunique()\n",
    "print('Number of categories is {}'.format(numb_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique items is 18712\n"
     ]
    }
   ],
   "source": [
    "numb_items = data_agg['item_id'].nunique()\n",
    "print('Number of unique items is {}'.format(numb_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore trends and seasonality in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature engineering  and train, test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps below will take significant amount of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test, X_predict, predict_extended = return_processed_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long cell of functions from app/train_model.py for training and evaluation, you can scroll down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "\n",
    "def build_model():\n",
    "    '''\n",
    "        build_model() - function that creates a model to later train, test and save for predicting\n",
    "        Input:\n",
    "            None \n",
    "        Output:\n",
    "            model - a sklearn GridSearchCV object, model to be trained on existing data and predict categories for the new data\n",
    "    '''\n",
    "\n",
    "    \n",
    "    parameters = {\n",
    "                #\"max_depth\"        : [ 1, 2, 6],\n",
    "                \"min_child_weight\" : [5, 30]\n",
    "    }        \n",
    "    # using GridSearch for optimization is not a good idea for time series since we can only test on future data\n",
    "    '''\n",
    "    cv_xgb = GridSearchCV(\n",
    "                XGBRegressor(\n",
    "                    max_depth=8,\n",
    "                    n_estimators=300,\n",
    "                    min_child_weight = 5,\n",
    "                    colsample_bytree=0.8, \n",
    "                    subsample=0.8, \n",
    "                    eta=0.3), \n",
    "                param_grid = parameters, n_jobs=-1, cv=3)\n",
    "    '''\n",
    "    #model = cv_xgb\n",
    "    model = XGBRegressor(n_estimators=300, min_child_weight = 5)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    '''\n",
    "        evaluate_model() - function that evaluates an sklearn model\n",
    "        Input:\n",
    "            model - a trained sklearn model capable of  'predict' methods\n",
    "            X_test - (pd.DataFrame) data for testing, features\n",
    "            y_test - (np.array) array with labels for testing, targets\n",
    "        Output:\n",
    "            MAE - (float) - mean absolute error across all shops and items montly data for period of time defined in X_test dataset\n",
    "    '''\n",
    "    # get the model prediction\n",
    "    y_pred = model.predict(X_test)\n",
    "    # make integers for meaningfull predictions\n",
    "    y_pred = y_pred.astype(int)\n",
    "    MAE = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    validate_act_vs_pred = pd.DataFrame(zip(y_test, y_pred), columns=['actual', 'prediction'])\n",
    "    validate_non_zero = validate_act_vs_pred[(validate_act_vs_pred['actual'] != 0) | (validate_act_vs_pred['prediction'] != 0)]\n",
    "    MAE_non_zero = mean_absolute_error(validate_non_zero['actual'], validate_non_zero['prediction'])\n",
    "    return MAE, MAE_non_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating a base estimator to compare with "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will try out 2 different possible base estimators.  The first base estimator will always predict the number of items sold in the next month to be the same as this month, the second estimator will predict next month sales as an average of the last 3 month sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's evaluate the first estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class base_estimator:\n",
    "    '''\n",
    "        base_estimator - class for returning basic prediction for items sold next month \n",
    "                        to compare with ML estimators\n",
    "        Parameters:\n",
    "            type_ - (str) type of base estimator, either 'last_month' (by default) which returns number of items sold this month,\n",
    "                    or 'last_three_months' which returns average of number of items sold last 3 months \n",
    "                    as the prediction of items sold next month\n",
    "    '''\n",
    "    def __init__(self, type_='last_month'):\n",
    "        self.type_ = type_\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        '''\n",
    "            predict() - method that returns predictions for the nest month items sold\n",
    "            Input:\n",
    "                X_test - (pd.DataFrame) dataframe with contains number of items sold in the past and this month\n",
    "            Output:\n",
    "                y_pred - (list) array of predictions for the items sold next month\n",
    "        '''\n",
    "        if self.type_ == 'last_month':\n",
    "            y_pred = np.array(X_test['item_cnt_month'])\n",
    "        elif self.type_ == 'last_three_months':\n",
    "            y_pred = np.array(X_test['item_cnt_roll_mean'])\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_last_month = base_estimator('last_month')\n",
    "estimator_last_3_months = base_estimator('last_three_months')\n",
    "mae1, mae_non_zero1 = evaluate_model(estimator_last_month, X_test, Y_test)\n",
    "mae2, mae_non_zero2 = evaluate_model(estimator_last_3_months, X_test, Y_test)\n",
    "print('For the first base estimator MAE and MAE non-zero on test data are {} and {}'.format(mae1, mae_non_zero1) )\n",
    "print('For the second base estimator MAE and MAE non-zero on test data are {} and {}'.format(mae2, mae_non_zero2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating and testing Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import HuberRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_pipeline = Pipeline(steps=[\n",
    "                    ('Scaler', StandardScaler()),\n",
    "                    ('Regressor', HuberRegressor())\n",
    "                  ])\n",
    "\n",
    "print('Training model...')\n",
    "\n",
    "linear_pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Evaluating model...')\n",
    "mae, mae_non_zero = evaluate_model(linear_pipeline, X_test, Y_test)\n",
    "print('MAE and MAE non-zero on test data are {} and {}'.format(mae, mae_non_zero) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating and testing XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can either train a new model or load a pre-trained one to save time depending on 'load_model' parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'load_model' is False then we re-train a model, else if True, we load some model\n",
    "load_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "\n",
    "if load_model:\n",
    "    print('Loading model...')\n",
    "    model = joblib.load(\"models/forecast_v2.pkl\")\n",
    "else:\n",
    "    print('Building model...')\n",
    "    model = XGBRegressor()        \n",
    "    print('Training model...')\n",
    "    model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Evaluating model...')\n",
    "mae, mae_non_zero = evaluate_model(model, X_test, Y_test)\n",
    "print('MAE and MAE non-zero on test data are {} and {}'.format(mae, mae_non_zero) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('XGBRegressor with this parameters turned out to be the best:', model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "print('Saving model...')\n",
    "file_pkl = open('models/forecast_v2.pkl', 'wb')\n",
    "pickle.dump(model, file_pkl)\n",
    "file_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  See what features are the most important for this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Using data on feature importance I've selected features to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_importance(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Tuning parameters and getting feature importance for the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_pipeline = Pipeline(steps=[\n",
    "                    ('Scaler', StandardScaler()),\n",
    "                    ('Regressor', HuberRegressor())\n",
    "                  ])\n",
    "\n",
    "print('Training model...')\n",
    "\n",
    "parameters = {\n",
    "                'Regressor__max_iter': [300, 400],\n",
    "                'Regressor__epsilon': [1.1, 1.2],\n",
    "            }        \n",
    "cv_linear = GridSearchCV(linear_pipeline, \n",
    "                         param_grid = parameters, \n",
    "                         n_jobs=-1, \n",
    "                         cv=TimeSeriesSplit(n_splits=3), \n",
    "                         scoring='neg_mean_absolute_error')\n",
    "\n",
    "cv_linear.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_linear.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Evaluating model...')\n",
    "mae, mae_non_zero = evaluate_model(cv_linear, X_test, Y_test)\n",
    "print('MAE and MAE non-zero on test data are {} and {}'.format(mae, mae_non_zero) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "print('Saving model...')\n",
    "file_pkl = open('models/forecast_linear_v1.pkl', 'wb')\n",
    "pickle.dump(cv_linear, file_pkl)\n",
    "file_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output feature importances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing on unseen shops "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on 10 shops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = preprocess_data('data/sales_train.csv', 'data/items.csv', use_shop_ids=range(30,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new, Y_train_new, X_test_new, Y_test_new, X_predict_new, predict_extended = return_processed_data(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use linear model for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "print('Loading model...')\n",
    "model = joblib.load(\"models/forecast_linear_v1.pkl\")\n",
    "\n",
    "print('Evaluating model...')\n",
    "mae, mae_non_zero = evaluate_model(model, X_test_new, Y_test_new)\n",
    "print('MAE and MAE non-zero on test data are {} and {}'.format(mae, mae_non_zero) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the shop from web app template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = preprocess_data('data/sales_train.csv', 'data/items.csv', use_shop_ids=[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new, Y_train_new, X_test_new, Y_test_new, X_predict_new, predict_extended = return_processed_data(data_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use linear model for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "print('Loading model...')\n",
    "model = joblib.load(\"models/forecast_linear_v1.pkl\")\n",
    "\n",
    "print('Evaluating model...')\n",
    "mae, mae_non_zero = evaluate_model(model, X_test_new, Y_test_new)\n",
    "print('MAE and MAE non-zero on test data are {} and {}'.format(mae, mae_non_zero) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
